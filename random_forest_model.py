# -*- coding: utf-8 -*-
"""code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oQZZvCM7T0-Ev_0p68kXg7Nb3a4UVCr4
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import joblib

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from google.colab import files

# Load the dataset
try:
    df = pd.read_csv("Life Expectancy Data.csv")
except FileNotFoundError:
    print("Error: Could not find 'Life Expectancy Data.csv' in the current directory.")
    print("Please make sure the data file is in the same directory as this script.")
    exit(1)

df.head() # ilk 5 satırı göster

print("Veri setindeki tüm sütunlar:")
for i, col in enumerate(df.columns):
    print(f"{i+1}. {col}")

#sayısal ve kategorik sınıfları ayrıştırma
numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
categorical_cols = df.select_dtypes(include=['object']).columns.tolist()

print("Sayısal (numerik) sütunlar:", numeric_cols)
print("\nKategorik sütunlar:", categorical_cols)

#sayısal özelliklerin dağılımı
df[numeric_cols].hist(bins=20, figsize=(15, 12), color='skyblue', edgecolor='black')
plt.suptitle("Sayısal Özelliklerin Dağılımı", fontsize=16)
plt.tight_layout(rect=[0, 0, 1, 0.96])
plt.show()

# Kategorik (object tipinde) tüm sütunları listele
categorical_cols = df.select_dtypes(include=['object']).columns.tolist()

print("Kategorik sütunlar:", categorical_cols)

for col in categorical_cols:
    print(f"\n📌 {col} → unique değerler:")
    print(df[col].unique())

# 'Status' gibi binary (2 sınıflı) kategorik sütunlar için One-Hot Encoding
df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)

missing = df.isnull().mean() * 100
missing = missing[missing > 0].sort_values()

plt.figure(figsize=(10, 8))
missing.plot(kind='barh', color='salmon')
plt.title("Eksik Veri Oranı (%)")
plt.xlabel("Yüzde")
plt.ylabel("Özellikler")
plt.grid(True, axis='x', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

# veri türlerinin dağılımı
type_counts = df.dtypes.value_counts()

plt.figure(figsize=(6,6))
plt.pie(type_counts, labels=type_counts.index.astype(str), autopct='%1.1f%%', startangle=90, colors=['#ff9999','#66b3ff'])
plt.title("Veri Türlerine Göre Özellik Dağılımı")
plt.axis('equal')
plt.show()

# Orijinal verinin bir kopyasını al (temizlenmemiş haliyle)
raw_df = pd.read_csv("Life Expectancy Data.csv") #temizlik öncesi verinin kopyası

# 2️⃣ Sayısal sütunlardaki eksik verileri ortalama ile dolduruyoruz
df = df.fillna(df.mean(numeric_only=True))

summary_df = pd.DataFrame({
    "Açıklama": ["Toplam Satır", "Toplam Sütun", "Toplam Eksik Hücre", "Eksik Veri Oranı (%)"],
    "Temizlik Öncesi": [
        raw_df.shape[0],
        raw_df.shape[1],
        raw_df.isnull().sum().sum(),
        round((raw_df.isnull().sum().sum() / raw_df.size) * 100, 2)
    ],
    "Temizlik Sonrası": [
        df.shape[0],
        df.shape[1],
        df.isnull().sum().sum(),
        round((df.isnull().sum().sum() / df.size) * 100, 2)
    ]
})

print(summary_df)

total_missing_raw = raw_df.isnull().sum().sum()
total_missing_clean = df.isnull().sum().sum()

plt.bar(["Temizlik Öncesi", "Temizlik Sonrası"], [total_missing_raw, total_missing_clean], color=["orange", "green"])
plt.ylabel("Eksik Hücre Sayısı")
plt.title("Toplam Eksik Hücre Sayısı (Karşılaştırmalı)")
plt.grid(axis='y', linestyle='--', alpha=0.6)
plt.show()

# 1️⃣ Hedef (bağımlı) değişkeni ayırıyoruz: 'Life expectancy '
# Modelin tahmin edeceği şey bu
y = df["Life expectancy "]

# 2️⃣ Girdi (bağımsız) değişkenleri ayırıyoruz: Geri kalan tüm sütunlar
# Modelin öğrenmesini sağlayacak özellikler
X = df.drop(columns=["Life expectancy "])

# 3️⃣ Eğitim ve test verilerine ayırıyoruz
# Eğitim verisi modelin öğrenmesi için (%80)
# Test verisi modelin doğruluğunu ölçmek için (%20)
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(
    X, y,              # Girdiler ve hedef
    test_size=0.2,     # %20 test verisi
    random_state=42    # Aynı sonuçları almak için sabit tohum değeri
)

# 1️⃣ Lineer Regresyon Modeli oluşturma
lr_model = LinearRegression()
lr_model.fit(X_train, y_train)

# 2️⃣ Test verisi üzerinde tahmin yap
y_pred_lr = lr_model.predict(X_test)

# 3️⃣ Metrikleri hesapla
mae_lr = mean_absolute_error(y_test, y_pred_lr)
rmse_lr = np.sqrt(mean_squared_error(y_test, y_pred_lr))
r2_lr = r2_score(y_test, y_pred_lr)

print("🔹 Linear Regression Sonuçları:")
print(f"MAE  : {mae_lr:.2f}")
print(f"RMSE : {rmse_lr:.2f}")
print(f"R²   : {r2_lr:.2f}")

# 4️⃣ Gerçek vs Tahmin Grafiği
plt.figure(figsize=(6,5))
plt.scatter(y_test, y_pred_lr, alpha=0.6, color='royalblue')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
plt.xlabel("Gerçek Yaşam Süresi")
plt.ylabel("Tahmin Edilen Yaşam Süresi")
plt.title("Linear Regression - Gerçek vs Tahmin")
plt.grid(True)
plt.tight_layout()
plt.show()

# 5️⃣ Artık (residual) dağılımı
residuals_lr = y_test - y_pred_lr
plt.figure(figsize=(6,4))
plt.hist(residuals_lr, bins=20, color='darkorange', edgecolor='black')
plt.title("Linear Regression - Artıkların Dağılımı")
plt.xlabel("Artık (Gerçek - Tahmin)")
plt.grid(True)
plt.tight_layout()
plt.show()

# Ne Sonuç Çıkarabiliriz?
#Lineer regresyon ortalama tahminlerde iyi iş çıkarıyor.

#Ancak bazı noktalar için doğrusal ilişki yetersiz kalıyor olabilir.

#Bu durumda:

#Non-lineer modeller (Decision Tree, Random Forest) denemek mantıklı olur.

#Ayrıca uç değerleri gözlemleyip filtrelemek model kalitesini artırabilir.

# 1️⃣ Decision Modeli oluştur ve eğit
dt_model = DecisionTreeRegressor(random_state=42)
dt_model.fit(X_train, y_train)

# 2️⃣ Tahmin yap
y_pred_dt = dt_model.predict(X_test)

# 3️⃣ Metrikleri hesapla
mae_dt = mean_absolute_error(y_test, y_pred_dt)
rmse_dt = np.sqrt(mean_squared_error(y_test, y_pred_dt))
r2_dt = r2_score(y_test, y_pred_dt)

# 4️⃣ Sonuçları yazdır
print("🌳 Decision Tree Regressor Sonuçları:")
print(f"MAE  : {mae_dt:.2f}")
print(f"RMSE : {rmse_dt:.2f}")
print(f"R²   : {r2_dt:.2f}")

# 5️⃣ Gerçek vs Tahmin Grafiği
plt.figure(figsize=(6,5))
plt.scatter(y_test, y_pred_dt, alpha=0.6, color='seagreen')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
plt.xlabel("Gerçek Yaşam Süresi")
plt.ylabel("Tahmin Edilen Yaşam Süresi")
plt.title("Decision Tree - Gerçek vs Tahmin")
plt.grid(True)
plt.tight_layout()
plt.show()

# 6️⃣ Artıkların Dağılımı
residuals_dt = y_test - y_pred_dt
plt.figure(figsize=(6,4))
plt.hist(residuals_dt, bins=20, color='forestgreen', edgecolor='black')
plt.title("Decision Tree - Artıkların Dağılımı")
plt.xlabel("Artık (Gerçek - Tahmin)")
plt.grid(True)
plt.tight_layout()
plt.show()

# 1️⃣ Random forest Modeli oluştur ve eğit
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# 2️⃣ Tahmin yap
y_pred_rf = rf_model.predict(X_test)

# 3️⃣ Metrikleri hesapla
mae_rf = mean_absolute_error(y_test, y_pred_rf)
rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))
r2_rf = r2_score(y_test, y_pred_rf)

# 4️⃣ Sonuçları yazdır
print("🌲 Random Forest Regressor Sonuçları:")
print(f"MAE  : {mae_rf:.2f}")
print(f"RMSE : {rmse_rf:.2f}")
print(f"R²   : {r2_rf:.2f}")

# 5️⃣ Gerçek vs Tahmin Grafiği
plt.figure(figsize=(6,5))
plt.scatter(y_test, y_pred_rf, alpha=0.6, color='darkblue')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
plt.xlabel("Gerçek Yaşam Süresi")
plt.ylabel("Tahmin Edilen Yaşam Süresi")
plt.title("Random Forest - Gerçek vs Tahmin")
plt.grid(True)
plt.tight_layout()
plt.show()

# 6️⃣ Artıkların Dağılımı
residuals_rf = y_test - y_pred_rf
plt.figure(figsize=(6,4))
plt.hist(residuals_rf, bins=20, color='steelblue', edgecolor='black')
plt.title("Random Forest - Artıkların Dağılımı")
plt.xlabel("Artık (Gerçek - Tahmin)")
plt.grid(True)
plt.tight_layout()
plt.show()

# Daha önce elde edilen sonuçları manuel olarak giriyoruz
comparison_df = pd.DataFrame({
    "Model": ["Linear Regression", "Decision Tree", "Random Forest"],
    "MAE": [2.86, 1.55, 1.05],
    "RMSE": [3.90, 2.55, 1.64],
    "R²": [0.82, 0.93, 0.97]
})

# Tabloyu yazdır
print("📊 Üç Modelin Performans Karşılaştırması")
display(comparison_df)

# Tüm grafiklerin yan yana gösterileceği 2 satır × 3 sütunluk grid yapısı
fig, axs = plt.subplots(2, 3, figsize=(18, 10))

# ============================
# Satır 1: Gerçek vs Tahmin
# ============================
axs[0, 0].scatter(y_test, y_pred_lr, alpha=0.6, color='royalblue')
axs[0, 0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
axs[0, 0].set_title("Linear Regression - Gerçek vs Tahmin")
axs[0, 0].set_xlabel("Gerçek")
axs[0, 0].set_ylabel("Tahmin")
axs[0, 0].grid(True)

axs[0, 1].scatter(y_test, y_pred_dt, alpha=0.6, color='seagreen')
axs[0, 1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
axs[0, 1].set_title("Decision Tree - Gerçek vs Tahmin")
axs[0, 1].set_xlabel("Gerçek")
axs[0, 1].grid(True)

axs[0, 2].scatter(y_test, y_pred_rf, alpha=0.6, color='darkorange')
axs[0, 2].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
axs[0, 2].set_title("Random Forest - Gerçek vs Tahmin")
axs[0, 2].set_xlabel("Gerçek")
axs[0, 2].grid(True)

# ============================
# Satır 2: Artık Dağılımı
# ============================
axs[1, 0].hist(y_test - y_pred_lr, bins=20, color='royalblue', edgecolor='black')
axs[1, 0].set_title("Linear Regression - Artıklar")
axs[1, 0].set_xlabel("Artık")
axs[1, 0].set_ylabel("Frekans")
axs[1, 0].grid(True)

axs[1, 1].hist(y_test - y_pred_dt, bins=20, color='seagreen', edgecolor='black')
axs[1, 1].set_title("Decision Tree - Artıklar")
axs[1, 1].set_xlabel("Artık")
axs[1, 1].grid(True)

axs[1, 2].hist(y_test - y_pred_rf, bins=20, color='darkorange', edgecolor='black')
axs[1, 2].set_title("Random Forest - Artıklar")
axs[1, 2].set_xlabel("Artık")
axs[1, 2].grid(True)

plt.suptitle("Model Performansı: Gerçek vs Tahmin ve Artıkların Karşılaştırması", fontsize=16)
plt.tight_layout(rect=[0, 0, 1, 0.96])
plt.show()

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import pandas as pd
import numpy as np

# 1️⃣ Eğitim ve test tahminleri
y_pred_train = rf_model.predict(X_train)
y_pred_test = rf_model.predict(X_test)

# 2️⃣ Metrikler
r2_train = r2_score(y_train, y_pred_train)
mae_train = mean_absolute_error(y_train, y_pred_train)
rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))

r2_test = r2_score(y_test, y_pred_test)
mae_test = mean_absolute_error(y_test, y_pred_test)
rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))

# 3️⃣ Karşılaştırmalı tablo
metrics_df = pd.DataFrame({
    "Veri Seti": ["Eğitim", "Test"],
    "R²": [r2_train, r2_test],
    "MAE": [mae_train, mae_test],
    "RMSE": [rmse_train, rmse_test]
})

# 4️⃣ Otomatik yorumlayıcı
print("📊 Overfitting/Underfitting Karşılaştırması\n")
display(metrics_df)

print("\n🔍 Yorumlama:")

r2_gap = r2_train - r2_test

if r2_gap > 0.1 and r2_test < 0.9:
    print("⚠️ Overfitting tespit edildi: Eğitim R² çok yüksek, test R² düşük.")
elif r2_train < 0.8 and r2_test < 0.8:
    print("📉 Underfitting tespit edildi: Model hem eğitim hem test verisinde başarısız.")
elif abs(r2_gap) <= 0.1 and r2_test >= 0.9:
    print("✅ Model genelleme başarısı yüksek. Overfitting / underfitting görünmüyor.")
else:
    print("ℹ️ Model dengeli olabilir, ancak skorlar incelenmeli.")

#Cross Validation hesaplaması

from sklearn.model_selection import cross_val_score
from sklearn.metrics import make_scorer

# R² için 5-fold cross-validation
cv_scores_r2 = cross_val_score(rf_model, X, y, cv=5, scoring='r2')

# MAE için 5-fold cross-validation (negatif döner, pozitif yapmak için ters çevrilir)
mae_scorer = make_scorer(mean_absolute_error, greater_is_better=False)
cv_scores_mae = cross_val_score(rf_model, X, y, cv=5, scoring=mae_scorer)

# Ortalama skorları yazdır
print("📊 Cross-Validation Skorları (5-Fold):")
print("R² Skorları:", np.round(cv_scores_r2, 4))
print("Ortalama R²:", np.mean(cv_scores_r2).round(4))
print("\nMAE Skorları:", np.round(-cv_scores_mae, 4))
print("Ortalama MAE:", (-np.mean(cv_scores_mae)).round(4))

mean_r2 = np.mean(cv_scores_r2)
mean_mae = -np.mean(cv_scores_mae)

# 7️⃣ Karşılaştırma tablosu
comparison_df = pd.DataFrame({
    "Metrik": ["R²", "MAE"],
    "Cross-Validation (Ortalama)": [mean_r2, mean_mae],
    "Test Skoru": [r2_test, mae_test]
})

# 8️⃣ Yazdır
print("📊 Cross-Validation vs Test Skoru Karşılaştırması")
print(comparison_df)

# Farkın yüzde cinsinden hesaplanması
r2_gap_percent = abs(r2_test - mean_r2) / r2_test * 100

print(f"📐 Test ve Cross-Validation R² farkı: {r2_gap_percent:.2f}%")

# Yorumlama
print("🔍 Yorumlama:")
if r2_gap_percent <= 5:
    print("✅ Model genelleme konusunda çok başarılı. Ezberleme (overfitting) yapmıyor.")
elif r2_gap_percent <= 10:
    print("🟡 Model genellemesi kabul edilebilir seviyede. Küçük fark doğal.")
else:
    print("❗ Model yüksek ihtimalle overfitting yapıyor. Farklı veri setlerinde performansı düşebilir.")

#En uygun model olarak random forest modeli seçildi.
#Cross- Validation ile genelleme bulundu. Belirli bir oranda overfitting olabilceği gözlemlendi.
#Overfitting riskinin azaltılması için Random forest modelini geliştirme aşamalarına geçildi.
#Random Forest modelini geliştirme adımlarına geçelim

#Features İmportance değerlerin bulunması

# 1️⃣ Özellik isimlerini ve önem skorlarını al
feature_names = X.columns  # Tüm orijinal öznitelik isimleri
importances = rf_model.feature_importances_  # Random Forest modeli üzerinden alınır
indices = np.argsort(importances)[::-1]  # Büyükten küçüğe sırala

# 2️⃣ Görsel olarak çiz (ilk 15 özellik için)
plt.figure(figsize=(12, 6))
plt.title("Random Forest - Özellik Önem Skoru")
plt.bar(range(15), importances[indices[:15]], align="center", color="mediumseagreen")
plt.xticks(range(15), feature_names[indices[:15]], rotation=90)
plt.xlabel("Özellikler")
plt.ylabel("Önem Skoru")
plt.tight_layout()
plt.show()

# 3️⃣ Tablo olarak da ilk 10 özelliği göster (opsiyonel)
top_features_df = pd.DataFrame({
    "Özellik": feature_names[indices],
    "Önem Skoru": importances[indices]
}).head(10)

top_features_df

# Eğitim verisinde tahmin yap
y_pred_train = rf_model.predict(X_train)

# Eğitim metrikleri
r2_train = r2_score(y_train, y_pred_train)
mae_train = mean_absolute_error(y_train, y_pred_train)
rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))
print(f"R2 değeri: {r2_train}")
print(f"MAE değeri: {mae_train}")
print(f"RMSE değeri: {rmse_train}")

#Hiperparametre optimizasyonu

from sklearn.model_selection import GridSearchCV

# Hiperparametre aralığı (hatalı 'auto' kaldırıldı)
param_grid = {
    'n_estimators': [100, 150],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5],
    'max_features': ['sqrt', 'log2']
}

grid_search = GridSearchCV(
    estimator=RandomForestRegressor(random_state=42),
    param_grid=param_grid,
    cv=5,
    scoring='r2',
    verbose=1,
    n_jobs=-1
)

grid_search.fit(X_train, y_train)

best_rf = grid_search.best_estimator_
y_pred_best = best_rf.predict(X_test)

from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error

r2_best = r2_score(y_test, y_pred_best)
mae_best = mean_absolute_error(y_test, y_pred_best)
rmse_best = np.sqrt(mean_squared_error(y_test, y_pred_best))  # düzeltildi

print("🔧 En iyi hiperparametreler:")
print(grid_search.best_params_)

print("\n✅ Optimize edilmiş modelin test skorları:")
print(f"R²: {r2_best:.3f}")
print(f"MAE: {mae_best:.3f}")
print(f"RMSE: {rmse_best:.3f}")

# 🔁 Optimize edilmiş model için cross-validation testleri
cv_scores_r2_opt = cross_val_score(best_rf, X, y, cv=5, scoring='r2')
mean_r2_opt = np.mean(cv_scores_r2_opt)

cv_scores_mae_opt = cross_val_score(best_rf, X, y, cv=5, scoring=make_scorer(mean_absolute_error, greater_is_better=False))
mean_mae_opt = -np.mean(cv_scores_mae_opt)

# 📋 Performans karşılaştırma tablosu
comparison_opt_df = pd.DataFrame({
    "Metrik": ["R²", "MAE"],
    "Cross-Validation (Ortalama)": [mean_r2_opt, mean_mae_opt],
    "Test Skoru": [r2_best, mae_best]
})

print("📊 Optimize Edilmiş Random Forest Model Performansı:")
print(comparison_opt_df)

# 📐 R² farkının yüzdesel olarak hesaplanması
r2_gap_percent_opt = abs(r2_best - mean_r2_opt) / r2_best * 100
print(f"\n📐 Test ve CV R² farkı: {r2_gap_percent_opt:.2f}%")

# 🔍 Yorumlama
print("🔍 Yorumlama:")
if r2_gap_percent_opt <= 5:
    print("✅ Model genelleme konusunda çok başarılı. Overfitting gözlemlenmiyor.")
elif r2_gap_percent_opt <= 10:
    print("🟡 Model kabul edilebilir düzeyde. Küçük bir fark doğal.")
else:
    print("❗ Overfitting riski olabilir. Test ve CV skorları arasında anlamlı fark var.")

#hiperparametre aralığının daraltılarak modeli kabul edilebilir düzeyden Genelleme konusunda başarılı hale dönüştürmek.

# Gerekli kütüphaneler
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.metrics import r2_score, mean_absolute_error, make_scorer

# 1️⃣ Veriyi yükle
df = pd.read_csv("Life Expectancy Data.csv")  # kendi yoluna göre değiştir
df = df.drop(columns=["Country"])
df = df.fillna(df.mean(numeric_only=True))
df = pd.get_dummies(df, columns=["Status"], drop_first=True)

# 2️⃣ Özellik ve hedef ayrımı
X = df.drop(columns=["Life expectancy "])
y = df["Life expectancy "]

# 3️⃣ Eğitim/test bölme
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 4️⃣ Daraltılmış hiperparametre aralığı
param_grid_narrow = {
    'n_estimators': [100, 120],
    'max_depth': [10, 15],
    'min_samples_split': [2, 4],
    'max_features': ['sqrt']
}

# 5️⃣ GridSearchCV tanımı
grid_search_narrow = GridSearchCV(
    estimator=RandomForestRegressor(random_state=42),
    param_grid=param_grid_narrow,
    cv=5,
    scoring='r2',
    verbose=1,
    n_jobs=-1
)

# 6️⃣ Modeli eğit
grid_search_narrow.fit(X_train, y_train)
best_rf_narrow = grid_search_narrow.best_estimator_

# 7️⃣ Test skorlarını hesapla
y_pred_narrow = best_rf_narrow.predict(X_test)
r2_test = r2_score(y_test, y_pred_narrow)
mae_test = mean_absolute_error(y_test, y_pred_narrow)

# 8️⃣ Cross-validation skorlarını hesapla
cv_scores_r2 = cross_val_score(best_rf_narrow, X, y, cv=5, scoring='r2')
mean_r2 = np.mean(cv_scores_r2)

cv_scores_mae = cross_val_score(
    best_rf_narrow, X, y, cv=5, scoring=make_scorer(mean_absolute_error, greater_is_better=False)
)
mean_mae = -np.mean(cv_scores_mae)

# 9️⃣ Fark yüzdesi
r2_gap_percent = abs(r2_test - mean_r2) / r2_test * 100

# 🔟 Raporlama
print("📊 Optimize Edilmiş Model Performansı:\n")
print(f"Test R²: {r2_test:.4f}")
print(f"CV Ortalama R²: {mean_r2:.4f}")
print(f"Test MAE: {mae_test:.4f}")
print(f"CV Ortalama MAE: {mean_mae:.4f}")
print(f"R² Test-CV Farkı (%): {r2_gap_percent:.2f}%\n")

# 📌 Yorumlama
print("🔍 Yorum:")
if r2_gap_percent <= 5:
    print("✅ Genelleme başarılı. Model overfitting yapmıyor.")
elif r2_gap_percent <= 10:
    print("🟡 Kabul edilebilir fark. Dikkatli olunmalı.")
else:
    print("❗ Overfitting riski var. CV ve test skoru arasında büyük fark var.")

# Save the model
joblib.dump(best_rf_narrow, 'life_expectancy_rf_model.pkl')

# Save the columns used for training (important for input order)
joblib.dump(list(X.columns), 'model_columns.pkl')